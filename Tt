# Import required libraries
import requests
import json
import pandas as pd
from pyspark.sql import SparkSession

def get_sharepoint_list_data(client_id, client_secret, tenant_id, site_id, list_id):
    """
    Retrieve data from a SharePoint list using Microsoft Graph API
    
    Parameters:
    -----------
    client_id : str
        Azure AD application ID
    client_secret : str
        Azure AD application secret
    tenant_id : str
        Azure AD tenant ID
    site_id : str
        SharePoint site ID or site URL path
    list_id : str
        SharePoint list ID or list name
        
    Returns:
    --------
    dict
        JSON response containing the SharePoint list items
    """
    # Get authentication token
    token_url = f"https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token"
    token_data = {
        'grant_type': 'client_credentials',
        'client_id': client_id,
        'client_secret': client_secret,
        'scope': 'https://graph.microsoft.com/.default'
    }
    
    token_response = requests.post(token_url, data=token_data)
    token_response.raise_for_status()
    access_token = token_response.json().get('access_token')
    
    # Set up headers for Graph API requests
    headers = {
        'Authorization': f'Bearer {access_token}',
        'Accept': 'application/json',
        'Content-Type': 'application/json'
    }
    
    # If site_id looks like a URL, extract the site identifier
    if site_id.startswith('https://'):
        # Get the site ID from the URL
        site_info_url = f"https://graph.microsoft.com/v1.0/sites/root:/{site_id.split('/')[-1]}"
        site_response = requests.get(site_info_url, headers=headers)
        site_response.raise_for_status()
        site_id = site_response.json().get('id')
    
    # If list_id is a name instead of ID, get the list ID
    if not list_id.startswith('{'):
        list_url = f"https://graph.microsoft.com/v1.0/sites/{site_id}/lists?$filter=displayName eq '{list_id}'"
        list_response = requests.get(list_url, headers=headers)
        list_response.raise_for_status()
        list_id = list_response.json().get('value')[0].get('id')
    
    # Get list items
    items_url = f"https://graph.microsoft.com/v1.0/sites/{site_id}/lists/{list_id}/items?$expand=fields"
    items_response = requests.get(items_url, headers=headers)
    items_response.raise_for_status()
    
    return items_response.json()

def process_sharepoint_data(response_data):
    """
    Process the SharePoint list data into a pandas DataFrame
    
    Parameters:
    -----------
    response_data : dict
        JSON response from the SharePoint list API call
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame containing the processed SharePoint list data
    """
    # Extract the items and their fields
    items = response_data.get('value', [])
    
    # Initialize a list to store processed items
    processed_items = []
    
    # Process each item
    for item in items:
        fields = item.get('fields', {})
        # Remove internal SharePoint fields
        for key in list(fields.keys()):
            if key.startswith('@'):
                fields.pop(key)
        processed_items.append(fields)
    
    # Convert to pandas DataFrame
    return pd.DataFrame(processed_items)

def sharepoint_to_databricks(client_id, client_secret, tenant_id, sharepoint_url, list_name):
    """
    Main function to extract SharePoint list data and load into a Databricks DataFrame
    
    Parameters:
    -----------
    client_id : str
        Azure AD application ID
    client_secret : str
        Azure AD application secret
    tenant_id : str
        Azure AD tenant ID
    sharepoint_url : str
        Full URL to the SharePoint site
    list_name : str
        Name of the SharePoint list
        
    Returns:
    --------
    pyspark.sql.DataFrame
        Databricks DataFrame containing the SharePoint list data
    """
    # Extract the site path from the URL
    site_path = '/'.join(sharepoint_url.split('/')[3:])
    
    # Get the list data from SharePoint
    list_data = get_sharepoint_list_data(client_id, client_secret, tenant_id, site_path, list_name)
    
    # Process the data into a pandas DataFrame
    pandas_df = process_sharepoint_data(list_data)
    
    # Convert to Spark DataFrame
    spark = SparkSession.builder.getOrCreate()
    spark_df = spark.createDataFrame(pandas_df)
    
    return spark_df

# Example usage
if __name__ == "__main__":
    # Replace these variables with your actual values
    client_id = "your-app-id"
    client_secret = "your-app-secret"
    tenant_id = "your-tenant-id"
    sharepoint_url = "https://your-tenant.sharepoint.com/sites/your-site"
    list_name = "Your List Name"
    
    # Extract data and create Databricks DataFrame
    df = sharepoint_to_databricks(client_id, client_secret, tenant_id, sharepoint_url, list_name)
    
    # Show the DataFrame
    df.show()
    
    # Optional: Save the DataFrame as a Delta table
    df.write.format("delta").mode("overwrite").saveAsTable("sharepoint_list_data")
